{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "checkpoint5_logistic regression",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mxrixA/Gomycode/blob/main/checkpoint5_logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvvyIj_j6ubx"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "#Preprocessing part1\n",
        "df=pd.read_csv(\"titanic-passengers.csv\",sep=(';')) #import file - copier lien de chemin- puis l'insérer dans la fonction pd.read csv\n",
        "df\n",
        "print(df.columns)  \n",
        "df.isnull().sum()\n",
        "df.describe()\n",
        "#\n",
        "nb_elements=len(df[\"Cabin\"]) #voir l'élement avec la plus grande fréquence\n",
        "print(\"nbr of elements\",nb_elements)\n",
        "print(df[\"Cabin\"].value_counts())\n",
        "#\n",
        "df[\"Cabin\"].fillna(value=\"G6\",inplace=True) #remplacer NaN values by G6\n",
        "df['Age'].fillna(df['Age'].mean(),inplace=True) #remplacer Nan values by the mean\n",
        "df\n",
        "\n",
        "############\n",
        "#Visualization part 2\n",
        "import seaborn as sns\n",
        "\n",
        "g = sns.FacetGrid(df,col=\"Sex\")\n",
        "g.map(sns.histplot,\"Age\")\n",
        "\n",
        "\n",
        "g = sns.FacetGrid(df,col=\"Survived\")\n",
        "g.map(sns.histplot,\"Age\")\n",
        "\n",
        "\n",
        "\n",
        "#####\n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsOWoM1hIzH5"
      },
      "source": [
        "def plot_correlation_map( df ):\n",
        "    corr = df.corr()\n",
        "    s , ax = plt.subplots( figsize =( 12 , 10 ) )\n",
        "    cmap = sns.diverging_palette( 220 , 10 , as_cmap = True )\n",
        "    s = sns.heatmap(\n",
        "        corr, \n",
        "        cmap = cmap,\n",
        "        square=True, \n",
        "        cbar_kws={ 'shrink' : .9 }, \n",
        "        ax=ax, \n",
        "        annot = True, \n",
        "        annot_kws = { 'fontsize' : 12 }\n",
        "        )\n",
        "plot_correlation_map(df)\n",
        "\n",
        "\n",
        "# this function gives us the correlation between every attribuate \n",
        "\n",
        "#we cant to see the impact of Home Adress on the variable Promoted\n",
        "cleanup={\"Survived\":{\"yes\":1, \"no\": 0}}  # at first, let's convert survives to numerical format\n",
        "df.replace(cleanup, inplace=True)\n",
        "df[[\"Pclass\", \"Survived\"]].groupby([\"Survived\"], as_index=True).mean()\n",
        "\n",
        "########\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie-Khm3JI4Q8"
      },
      "source": [
        "x=df.corr()\n",
        "sns.heatmap(x, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZQ6OZwmI78J"
      },
      "source": [
        "#create new column TITLE and drop useless columns\n",
        "df=df.drop(['PassengerId','SibSp','Parch', 'Ticket', 'Cabin', 'Embarked'],axis=1)\n",
        "l = [name[name.find(',')+2: name.find('.')] for name in df['Name']]\n",
        "df['title']=pd.DataFrame(l)\n",
        "df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uduUJnk0MJpp"
      },
      "source": [
        "sns.pairplot(df, hue='Survived', size=2.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXQADKurTEq3"
      },
      "source": [
        "#Label encoding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK1E_15jTsSQ"
      },
      "source": [
        "df[\"Survived\"]=df[\"Survived\"].map({\"yes\": 1, \"no\": 0})   #convert survived variable into numerical\n",
        "df.head()\n",
        "df[\"Sex\"]=df[\"Sex\"].map({\"male\": 1, \"female\": 0}) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGwD9eaEK0Mm"
      },
      "source": [
        "#import relevant libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "#features extraction\n",
        "X =df['Sex','Fare']\n",
        "y = df['Survived']\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=0)  #splitting data with test size of 25%\n",
        "\n",
        "logreg = LogisticRegression()   #build our logistic model\n",
        "logreg.fit(x_train, y_train)  #fitting training data\n",
        "y_pred  = logreg.predict(x_test)    #testing model’s performance\n",
        "\n",
        "print(\"Accuracy={:.2f}\".format(logreg.score(x_test, y_test)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmRKAfU6NtN6"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.regplot(x='gmat',y='admitted',data=data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqYkqe3UNtyq"
      },
      "source": [
        "confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
        "sns.heatmap(confusion_matrix, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}