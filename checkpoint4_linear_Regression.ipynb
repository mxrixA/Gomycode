{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "checkpoint4_linear Regression",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mxrixA/Gomycode/blob/main/checkpoint4_linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wohSVJXP7Zod"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "#Preprocessing part1\n",
        "df=pd.read_csv(\"kc_house_data.csv\") #import file - copier lien de chemin- puis l'insérer dans la fonction pd.read csv\n",
        "df\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY5oW2v-CaYB"
      },
      "source": [
        "print(df.columns)  \n",
        "\n",
        "df.isnull().sum()\n",
        "\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCUrnXkFD_jB"
      },
      "source": [
        "import seaborn as sns\n",
        "df['bedrooms'].value_counts().plot(kind='bar')\n",
        "plt.title('number of bedrooms')\n",
        "\n",
        "plt.ylabel('count')\n",
        "sns.despine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NznVzpRvLhAr"
      },
      "source": [
        "\n",
        "df=df.drop(['sqft_lot15'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30ZBy5Q1Iola"
      },
      "source": [
        "def plot_correlation_map( df ):\n",
        "    corr = df.corr()\n",
        "    s , ax = plt.subplots( figsize =( 12 , 10 ) )\n",
        "    cmap = sns.diverging_palette( 220 , 10 , as_cmap = True )\n",
        "    s = sns.heatmap(\n",
        "        corr, \n",
        "        cmap = cmap,\n",
        "        square=True, \n",
        "        cbar_kws={ 'shrink' : .9 }, \n",
        "        ax=ax, \n",
        "        annot = True, \n",
        "        annot_kws = { 'fontsize' : 12 }\n",
        "        )\n",
        "plot_correlation_map(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyOCqKcLKnrx"
      },
      "source": [
        "plt.scatter(df.price,df.sqft_living)\n",
        "plt.title(\"price VS sqft Living\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPssEBzxO7hF"
      },
      "source": [
        "plt.scatter(df.price,df.grade)\n",
        "plt.title(\"price VS grade\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5jKzt3pPaoL"
      },
      "source": [
        "plt.scatter(df.price,df.sqft_above)\n",
        "plt.title(\"price VS sqft above\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNcjhiC8SxG0"
      },
      "source": [
        "import seaborn as sb \n",
        "sb.distplot(df['price'], color = 'r')\n",
        "plt.title('Sale Price Distribution', fontsize = 16)\n",
        "plt.xlabel('price', fontsize = 14)\n",
        "plt.ylabel('Frequency', fontsize = 14)\n",
        "plt.xticks(fontsize = 12)\n",
        "plt.yticks(fontsize = 12)\n",
        "\n",
        "plt.savefig('distplot.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtPX2BF4YA3v"
      },
      "source": [
        "#selecting the most important features \n",
        "depending on the table of correlation , we will eliminate the data with price correlation less than 0,2 because it's useless and has no  strong relation with the price (which is our output)\n",
        "#the features selected are : \n",
        "bathrooms/bedrooms/sqrt_living/floors/view/grade/sqrt_above/yr_renovated "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zftv-BN1YUj_"
      },
      "source": [
        "\n",
        "sb.pairplot(df, size=2.5)\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-LvDu3da5vi"
      },
      "source": [
        "# create x and y\n",
        "feature_cols = 'sqft_living' \n",
        "x = df[feature_cols] # features\n",
        "y = df.price # output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35P3NsxacXH5"
      },
      "source": [
        "# Import 'train_test_split'\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Shuffle and split the data into training and testing subsets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state = 42)\n",
        "\n",
        "# Success\n",
        "print(\"Training and testing split was successful.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJvek8emdyGa"
      },
      "source": [
        "#linear regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icE4DLCAd14i"
      },
      "source": [
        "\n",
        "#extract x and y from our data\n",
        "x=df[\"sqft_living\"].values[:,np.newaxis]\n",
        "y=df[\"price\"].values\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=30) #splitting data with test size of 20%\n",
        "\n",
        "model=LinearRegression()   #build linear regression model\n",
        "model.fit(x_train,y_train)  #fitting the training data\n",
        "predicted=model.predict(x_test) #testing our model’s performance\n",
        "\n",
        "\n",
        "print(\"MSE\", mean_squared_error(y_test,predicted))\n",
        "print(\"R squared\", metrics.r2_score(y_test,predicted))\n",
        "\n",
        "reg = LinearRegression().fit(x, y)\n",
        "a=print(reg.coef_)\n",
        "b= print(reg.intercept_)\n",
        "\n",
        "predicted[1000] #????????????? manual result=237042,26 .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnoitFVA1pI2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yabk5OrRqgUv"
      },
      "source": [
        "plt.scatter(x,y,color=\"r\")\n",
        "plt.title(\"Linear Regression\")\n",
        "plt.ylabel(\"price\")\n",
        "plt.xlabel(\"sqft_living\")\n",
        "plt.plot(x,model.predict(x),color=\"k\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkuDt-aD3Eck"
      },
      "source": [
        "#Multi lineare regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWwQAmTA4LnK"
      },
      "source": [
        "#extract x and y from our data\n",
        "x=df[[\"sqft_living\",\"grade\"]]  #we have more than one input\n",
        "y=df[\"price\"].values\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.35,random_state=40) #splitting data with test size of 35%\n",
        "\n",
        "model=LinearRegression() #build linear regression model\n",
        "model.fit(x_train,y_train) #fitting the training data\n",
        "predicted=model.predict(x_test) #testing our model’s performance\n",
        "\n",
        "print(\"MSE\", mean_squared_error(y_test,predicted))\n",
        "print(\"R squared\", metrics.r2_score(y_test,predicted))\n",
        "\n",
        "reg = LinearRegression().fit(x, y)\n",
        "a=print(reg.coef_)\n",
        "b=print(reg.intercept_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5COYvSl9vJ2"
      },
      "source": [
        "#Polynomial regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q95AVck9zf1"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures \n",
        "\n",
        "x=df[[\"sqft_living\",\"grade\"]]  #we have more than one input\n",
        "y=df[\"price\"].values\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.35, random_state=40)  #splitting data\n",
        "lg=LinearRegression()\n",
        "poly=PolynomialFeatures(degree=3)\n",
        "\n",
        "x_train_fit = poly.fit_transform(x_train) #transforming our input data\n",
        "lg.fit(x_train_fit, y_train)\n",
        "x_test_ = poly.fit_transform(x_test)\n",
        "predicted = lg.predict(x_test_)\n",
        "\n",
        "print(\"MSE: \", metrics.mean_squared_error(y_test, predicted))\n",
        "print(\"R squared: \", metrics.r2_score(y_test,predicted))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyMeH_d0-Vl_"
      },
      "source": [
        "Polynomial regression is more exact than multi linear regression . (comparing the two correlation coeff)\n",
        "multi linear regression is better than linear regression .\n"
      ]
    }
  ]
}